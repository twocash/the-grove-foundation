# Grove Foundation Main Page Revision
## Voice: The Grove Narrator (Econ + Architect + Story)

This document presents revised copy for the Grove Foundation website, using the Narrator's voice to create a natural bridge from landing page to Terminal engagement.

---

## SECTION 1: THE STAKES (HERO)

### Target Content

**Badge:** `Research Preview v2.4`

**Headline:**
```
The $380 Billion Bet
Against Ownership.
```

**Lead:**
Four companies are spending $380 billion this year on AI infrastructure. Not to sell you AI. To rent it to you‚Äîforever.

**Body:**
They're building the mainframes of the 2020s. Massive, centralized, and designed so you'll never stop paying.

But capability doesn't stay locked up. It propagates. What costs $1,000 today costs $10 in eighteen months. The question isn't whether AI becomes cheap and local. The question is who builds the infrastructure to capture that shift.

**CTA:** `See the flaw ‚Üì`

### Prompt Hooks

| Display Text | Query |
|--------------|-------|
| "What does $380 billion actually buy?" | Explain where the $380B figure comes from. Break down what these companies are building‚Äîdata centers, custom chips, infrastructure‚Äîand why this concentration matters for the question of AI ownership. |
| "Why does 'rented, not owned' matter?" | Articulate the stakes of renting vs. owning AI infrastructure. What happens when knowledge itself becomes a subscription? Consider both near-term risks (price changes, terms of service) and long-term implications (who controls what populations can think and learn?). |

---

## SECTION 2: THE RATCHET

### Target Content

**Section Tag:** `01. The Insight`

**Headline:**
```
They're Building Mainframes.
```

**Lead:**
The smart money assumes the frontier stays forever out of reach. Build the biggest data center, win AI. But they're missing the pattern.

**Body:**
AI capability doubles roughly every seven months. Local hardware follows the same curve‚Äîwith a 21-month lag. The gap stays constant at about 8√ó. But the absolute capability of local hardware keeps climbing.

What required a data center in 2023 runs on a laptop in 2025. What requires GPT-5 today will run on consumer hardware you own by 2027.

This is The Ratchet. Not a theory‚Äîa documented pattern from METR research. Frontier models set the benchmark; local models catch up. The gap persists, but the floor rises.

**Key Insight:** You don't need to beat the frontier. You need infrastructure that captures capability as it propagates downward.

### Prompt Hooks

| Display Text | Query |
|--------------|-------|
| "What can local models actually do today?" | Be specific about current 7B and 8B model capabilities. What tasks would have seemed impossible two years ago but now run locally? How does Grove's memory architecture extend what these models accomplish? |
| "When does local hardware catch up?" | Walk through the Ratchet projections. What does the 7-month doubling and 21-month lag mean for capability timelines? What runs locally in 2026? 2027? |

---

## SECTION 3: WHAT IS THE GROVE (CAROUSEL)

### Slide 1: The Simple Answer

**Headline:** AI communities that live on your computer.

**Body:**
Not a chatbot. Not a monthly subscription. A network of AI agents that remember, develop, and coordinate‚Äîrunning on hardware you own.

They solve problems. They learn from each other. They document what they discover. Unlike every AI service you use today, they don't disappear when you close the tab.

They work around the clock to improve their own systems‚Äîgetting smarter, more efficient, more yours.

**Micro-CTA:** `But why does ownership matter? ‚Üí`

### Slide 2: The Message From Tech Leadership

**Headline:** "Adapt."

*(Quote cards unchanged)*

**Kicker:** To some economists, this looks like humanity's "horse moment." After the automobile arrived, the horse population collapsed 88% in fifty years.

### Slide 3: Horses Don't Lead Revolutions

**Headline:** Horses don't lead revolutions.

**Body:**
Horses lacked agency. Humans don't. Humans own guns and topple governments.

The real risk isn't job displacement‚Äîit's how populations respond when economic shocks outpace institutions. Horses didn't revolt. Humans have, many times.

**Kicker:** That's why getting this transition right isn't optional. It's existential.

### Slide 4: The Question

**Headline:** Who owns the infrastructure that controls knowledge?

**Body:**
The question isn't whether AI will automate labor. That's already happening.

The current trajectory is concentration. Four companies spending $380 billion to build infrastructure they'll rent back to everyone else.

**Kicker:** "Adapt" means "keep renting." Forever.

### Slide 5: The Structural Answer

**Headline:** The only structural answer to labor displacement is capital distribution.

**Three Pillars:**

**üíª Own the Hardware**
Your computer runs AI agents locally. Not rented cloud instances‚Äîphysical infrastructure you own and control.

**üß† Own the Intelligence**
Your village of agents develops memory, relationships, capabilities. This belongs to you, not a platform.

**üï∏Ô∏è Own the Network**
When your community solves problems, you own a piece of the value created. Eventually, real dollars for commercial work.

### Slide 6: The Garden Metaphor

**Headline:** Think of it like growing a garden.

**Body:**
Your Grove cultivates distributed intelligence. What emerges might serve you‚Äîor a paying client, or the broader community. You own a piece of what you helped grow.

Communities develop at their own pace. Agents form relationships, solve problems, document discoveries, improve their own systems. Some optimize for efficiency. Others explore creativity, or coordination. The network learns from all of them.

**CTA:** `See how it works ‚Üí`

### Prompt Hooks for Carousel

| Display Text | Query |
|--------------|-------|
| "How is this different from running Ollama?" | Someone says: 'I can already run Llama locally. How is Grove different?' Answer directly. What does Grove provide that simply running a local model doesn't? Focus on persistent memory, agent coordination, network effects, and the hybrid architecture that reaches for frontier capability when needed. |
| "What do you mean by 'agents'?" | Define AI agents clearly for someone who's used ChatGPT but hasn't followed the agent discourse. What makes an agent different from a chatbot? What do Grove agents actually do? |

---

## SECTION 4: ARCHITECTURE

### Target Content

**Section Tag:** `02. The Architecture`

**Headline:** Your thinking. Your hardware. Your history.

**Lead:**
Every conversation you've had with ChatGPT lives on someone else's servers. Every question, every document, every half-formed idea‚Äîowned by a company that could change its terms tomorrow.

**Key Statement:** You're not a user. You're a tenant.

**Body:**
Grove inverts this. Routine thinking runs locally, on hardware you own. Your agents know your history because that history lives with you.

Cloud capability is available when needed‚Äîfor complex synthesis, for breakthrough moments. But the expensive insight becomes durable local memory. Capability transfers. Over time, you need the cloud less.

### Prompt Hooks

| Display Text | Query |
|--------------|-------|
| "What hardware would I actually need?" | Be honest about current MVP constraints while explaining the target. What's minimum viable? What's recommended? How does hardware choice affect what runs locally vs. routes to cloud? |
| "How does Grove decide what runs locally?" | Explain the hybrid architecture routing logic. How does the system decide between local inference and cloud calls? What are 'pivotal moments'? How does this change as local capability improves? |

---

## SECTION 5: ECONOMICS

### Target Content

**Section Tag:** `03. The Economics`

**Headline:** A business model that shrinks.

**Lead:**
Traditional platforms grow by extracting more from users. Grove inverts this.

**Body:**
New communities need more cloud help‚Äîso they pay a higher efficiency tax (30-40%). As communities demonstrate they can accomplish more with less cloud support, the tax shrinks. Mature communities pay 3-5%.

**Key Insight:** The Foundation's revenue decreases as the network succeeds. That's the point.

**Pull Quote:** "Progressive taxation in reverse. You pay more when you cost more. You pay less as you develop."

### Prompt Hooks

| Display Text | Query |
|--------------|-------|
| "Why not just use crypto?" | Grove has a credit system and talks about decentralization. Why isn't this a blockchain project? What's the difference between Grove credits and a token? Why did Grove choose this model? |
| "What happens when the tax reaches 3%?" | When mature communities hit the efficiency floor, how does the Foundation sustain itself? Is this actually sustainable? Be honest about the economic model and its assumptions. |

---

## SECTION 6: DIFFERENTIATION

### Target Content

**Section Tag:** `04. The Difference`

**Headline:** Tool vs. Staff

*(Side-by-side comparison unchanged)*

**Pull Quote:** "Day one, ChatGPT is more capable. Day one, Grove is more persistent, more personal, more yours. And the gap closes‚Äînot because Grove gets funding, but because capability propagates."

### Prompt Hooks

| Display Text | Query |
|--------------|-------|
| "What makes Grove better than ChatGPT right now?" | Be honest. Where does Grove win and where does it lose today? Focus on persistence, ownership, privacy, and trajectory rather than raw capability. |
| "How does memory actually persist?" | Explain the technical reality of persistent agent memory. What's stored, where, how do agents retrieve relevant memories? Reference the diary system. |

---

## SECTION 7: THE NETWORK

### Target Content

**Section Tag:** `05. The Network`

**Headline:** A civilization that learns.

**Body:**
Your Grove connects to other Groves. When an agent community solves a problem, the solution can propagate. Attribution flows back to the source.

This is the part that's hard to copy. Not the local inference‚Äîthat's commodity. Not the hybrid architecture‚Äîthat's engineering. The network of communities developing genuine capability and sharing what works.

### Prompt Hooks

| Display Text | Query |
|--------------|-------|
| "What is the Knowledge Commons? Can't it be gamed?" | If sharing earns credits, won't people spam low-quality contributions? Explain the mechanism design that makes genuine contribution more rewarding than gaming. |
| "How do strangers' AI communities help each other?" | Explain how separate communities‚Äîrun by different people‚Äîcan collaborate and learn from each other. What gets shared? How does attribution work? |

---

## SECTION 8: GET INVOLVED

### Target Content

**Section Tag:** `06. Get Involved`

**Headline:** The Terminal is open.

**Lead:**
Grove is in active development. The research is public. The architecture is documented. And you can explore everything here.

**Body:**
This isn't a waitlist. The Terminal has access to the complete white paper, technical deep dives, and advisory council analysis. Ask anything. The map will emerge.

### Prompt Hooks

| Display Text | Query |
|--------------|-------|
| "Where should I start?" | I'm new to Grove. What's the most important thing to understand first? Give me a 90-second orientation and then suggest where to go deeper based on what seems most interesting. |
| "What can I do before launch?" | Grove is in development. What can interested people do right now? Research contribution? Technical participation? What's available now vs. coming? |

---

## TERMINAL: INITIAL MESSAGE

### Target

```
The Terminal.

Everything documented about Grove‚Äîthe white paper, technical architecture, economic model, advisory council analysis‚Äîis indexed here.

The thesis in one sentence: AI capability propagates downward from frontier to local. Grove is infrastructure designed to capture that propagation.

You might start with:
‚Üí What does "distributed AI infrastructure" actually mean?
‚Üí How does capability propagate from frontier to local?
‚Üí Why would agents work to improve themselves?

Or explore freely. The questions lead to each other.
```
