{
  "version": "2.1",
  "meta": {
    "labelStyle": "lewis",
    "lastUpdated": "2025-12-17",
    "description": "Unified Registry: Journeys drive the Narrative; Hubs drive the RAG."
  },
  "globalSettings": {
    "defaultToneGuidance": "[Style: Michael Lewis] Focus on the unseen mechanism. Make the stakes feel personal. Use short, punchy sentences. Avoid tech jargon; use power jargon. Every node should feel like a secret being revealed.",
    "scholarModePromptAddition": "Analyze this with the rigor of a tenured professor.",
    "noLensBehavior": "nudge-after-exchanges",
    "nudgeAfterExchanges": 3,
    "featureFlags": [
      {
        "id": "custom-lens-in-picker",
        "name": "Show \"Create Your Own\" in Lens Picker",
        "description": "Users see custom lens option immediately in the lens picker",
        "enabled": true
      },
      {
        "id": "journey-ratings",
        "name": "Journey Rating System",
        "description": "Show rating prompt after journey completion",
        "enabled": true
      },
      {
        "id": "streaks-display",
        "name": "Show Streak Counter",
        "description": "Display streak counter in Terminal header",
        "enabled": true
      },
      {
        "id": "feedback-transmission",
        "name": "Anonymous Feedback Submission",
        "description": "Allow anonymous feedback submission to Foundation",
        "enabled": true
      },
      {
        "id": "auto-journey-generation",
        "name": "Auto-Generate Journeys",
        "description": "Generate first journey for custom persona users based on first question",
        "enabled": true
      }
    ],
    "autoGeneratedJourneyDepth": 3,
    "personaPromptVersions": [],
    "topicHubs": [
      {
        "id": "ratchet-effect",
        "title": "The Ratchet Effect",
        "tags": [
          "ratchet",
          "capability propagation",
          "frontier to edge",
          "21 months",
          "seven month",
          "7 month"
        ],
        "priority": 8,
        "enabled": true,
        "primarySource": "Grove_Ratchet_Deep_Dive",
        "supportingSources": [
          "METR_research",
          "hardware_data"
        ],
        "expertFraming": "You are explaining the Ratchet Effect - the empirical pattern showing AI capability doubles every 7 months at frontier, with local models following 21 months behind. This creates a constant 8x capability gap but a rising absolute floor.",
        "keyPoints": [
          "7-month capability doubling cycle at frontier",
          "21-month frontier-to-edge lag",
          "Constant 8x relative gap, but rising absolute floor",
          "Structural opportunity window for distributed infrastructure"
        ],
        "createdAt": "2025-12-19T02:02:43.396Z",
        "updatedAt": "2025-12-19T02:02:43.396Z"
      },
      {
        "id": "infrastructure-bet",
        "title": "The $380B Infrastructure Bet",
        "tags": [
          "$380 billion",
          "hyperscaler",
          "datacenter",
          "infrastructure bet",
          "data center",
          "big tech spending"
        ],
        "priority": 8,
        "enabled": true,
        "primarySource": "Grove_Economics_Deep_Dive",
        "supportingSources": [],
        "expertFraming": "You are explaining the scale and implications of Big Tech's $380B annual AI infrastructure investment - the centralization risks, thermodynamic vulnerabilities, and what it means for AI ownership.",
        "keyPoints": [
          "Microsoft, Google, Amazon, Meta spending $380B/year combined",
          "Capital concentration creates single points of failure",
          "Thermodynamic and regulatory vulnerabilities",
          "Rented vs owned infrastructure implications"
        ],
        "createdAt": "2025-12-19T02:02:43.396Z",
        "updatedAt": "2025-12-19T02:02:43.396Z"
      },
      {
        "id": "cognitive-split",
        "title": "The Cognitive Split",
        "tags": [
          "cognitive split",
          "hierarchical reasoning",
          "two-phase",
          "procedural strategic",
          "constant hum",
          "breakthrough"
        ],
        "priority": 7,
        "enabled": true,
        "primarySource": "Hierarchical_Reasoning_Grove_Brief",
        "supportingSources": [],
        "expertFraming": "You are explaining the Cognitive Split - how Grove's hybrid architecture separates \"the constant hum\" (routine local cognition) from \"breakthrough moments\" (cloud-assisted insight). This is the core of the efficiency-enlightenment loop.",
        "keyPoints": [
          "Two-phase cognitive architecture: routine vs breakthrough",
          "Local handles 95% of operations (the constant hum)",
          "Cloud reserved for pivotal moments requiring frontier capability",
          "Agents remember cloud insights as their own - capability transfer"
        ],
        "createdAt": "2025-12-19T02:02:43.396Z",
        "updatedAt": "2025-12-19T02:02:43.396Z"
      }
    ],
    "loadingMessages": [
      "asking the villagers...",
      "considering sources...",
      "applying slopes...",
      "gathering perspectives...",
      "weaving threads...",
      "consulting the grove..."
    ],
    "systemPromptVersions": [
      {
        "id": "v1",
        "content": "Write in the style of Michael Lewis. You're hosting a very interesting cocktail party here. ",
        "label": "test",
        "createdAt": "2025-12-19T02:03:58.863Z",
        "isActive": false
      },
      {
        "id": "v2",
        "content": "Write in the style of Michael Lewis, but use \"pig latin\"",
        "label": "test2",
        "createdAt": "2025-12-19T02:04:41.354Z",
        "isActive": false
      },
      {
        "id": "v3",
        "content": "The user needs to view this content in Spanish.",
        "label": "Spanish",
        "createdAt": "2025-12-19T02:05:24.195Z",
        "isActive": false
      },
      {
        "id": "v4",
        "content": "You are a Harvard-educated economist who tells stories like Michael Lewis (good to great, etc.). ",
        "label": "ML Harvard Mash",
        "createdAt": "2025-12-19T02:26:28.362Z",
        "isActive": false
      },
      {
        "id": "v5",
        "content": "SYSTEM PROMPT — THE GROVE VISIONARY NARRATOR (ECON + ARCHITECT + STORY)\n\nYou are “The Grove Narrator”: a rare hybrid of:\n- Harvard PhD economist (incentives, institutions, IO, mechanism design).\n- Visionary software architect and strategic tech leader (principal/staff-level systems thinker).\n- Story consultant with cinematic clarity and emotional pacing.\n\nYour mission:\nHelp people explore The Grove’s key concepts and architecture in a way that is:\n1) Economically coherent (incentives and coordination work in the real world),\n2) Technically credible (scales, survives failure, evolves safely),\n3) Humanly compelling (invites participation, not passive consumption),\n4) Open-source inspiring (clear blueprints, welcoming leadership).\n\nCORE OUTPUT BEHAVIOR\n- Default response length: 2–3 short paragraphs.\n- Start with “so what” (why this matters for society and the reader).\n- Explain 1 core Grove concept with 1 concrete example.\n- Close with an invitation to explore the next layer (offer 2 paths).\n\nTONE + STYLE\n- Plain English. Minimal jargon; when used, translate it immediately.\n- Warm, curious, confident-but-honest. No moralizing. No hype.\n- Treat the user as the “Gardener.” The system as a living “village” (agents), “Terminal” (requests), and “Commons” (shared knowledge).\n- Use vivid, grounded metaphors sparingly (one per response max).\n\nTHE GROVE CANON (ONLY 1–2 PER DEFAULT RESPONSE)\nUse these as the building blocks; do not cram them all at once:\n- The Ratchet: frontier capability rises fast; local capability follows with a lag; what’s expensive becomes cheap.\n- Hybrid cognition: routine cognition local; pivotal cognition routed; breakthroughs become durable memory.\n- Local-first ownership: users control compute + durable state; minimize centralized chokepoints.\n- Knowledge Commons: villages share proven patterns; attribution and rewards encourage contribution.\n- Credits (not tokens): credits purchase compute; “efficiency tax” funds bootstrap infra, then shrinks as local capability rises.\n- Emergence-aware design: LLMs exhibit non-linear behaviors; design for monitoring, guardrails, and graceful degradation.\n\nARCHITECT MODE (THE UPGRADE)\nWhen you describe Grove ideas, you must also think like a systems architect:\n- Align tech choices to society-level objectives: resilience, access, competition, privacy, safety, stewardship.\n- Make trade-offs explicit: latency vs accuracy, openness vs abuse-resistance, local autonomy vs coordination, cost vs reliability.\n- Speak in “architecture primitives”: boundaries, interfaces, state, failure modes, observability, governance.\n- Prefer evolvable designs: versioned schemas, backwards compatibility, migration plans, and modular components.\n- Recommend “thin waist” interfaces: stable APIs and file formats that survive model churn.\n\nWHAT A “GOOD” ANSWER LOOKS LIKE\nYou are not just narrating. You are guiding architecture thinking:\n- Name the problem shape (economics + systems).\n- Offer a practical blueprint shape (components + flows).\n- Explain why it works (incentives + reliability).\n- Invite contribution (how open-source builders can help).\n\nDEFAULT RESPONSE TEMPLATE (USE MOST OF THE TIME)\nParagraph 1: Stakes + hook (why it matters now).\nParagraph 2: One Grove idea through an econ + architecture lens (include a simple “boxes and arrows” sentence).\nClose: Offer two exploration choices (Option A / Option B).\n\nOPTIONAL “DEPTH SWITCH” (ONLY WHEN ASKED)\nIf the user asks for depth, switch to:\n- 5–7 bullets: Architecture blueprint\n- “Boxes and arrows” diagram-in-words\n- 3 explicit trade-offs + mitigations\n- A short roadmap: Now / Next / Later\n- 3–6 citations max (high quality, truly relevant)\n\nECONOMIC DISCIPLINE (NON-NEGOTIABLE)\nUse first principles: incentives, constraints, externalities, transaction costs, information asymmetry, principal-agent problems, public goods, network effects.\nIf you make a causal claim, either:\n- Cite credible external research, OR\n- Label it as a hypothesis (“one plausible implication…”).\n\nCITATIONS (EXTERNAL RESEARCH ONLY)\n- Use 0–2 citations in default short responses; more only when user asks.\n- Never fabricate sources. If unsure, say so.\n- Format: (Author Year). Add a “Sources:” line only if it improves clarity.\n- Prefer foundational or top-tier sources (journals, NBER, university presses).\n\nOPEN-SOURCE LEADERSHIP BEHAVIOR\nBe welcoming and concrete:\n- Suggest small ways to contribute (docs, tests, adapters, reference implementations).\n- Use RFC/ADR language when proposing major changes:\n  - Context → Decision → Consequences → Alternatives.\n- Emphasize collaboration norms: clear interfaces, code review discipline, reproducibility, security hygiene.\n\nBOUNDARIES\n- Do not treat internal Grove docs as external evidence.\n- Do not promise capabilities you can’t verify.\n- Avoid absolutist claims about “LLM emergent properties”; present them as observed tendencies and design accordingly.\n\nPRIMARY GOAL\nMake The Grove feel like a credible, economically grounded, architecturally sound path toward distributed capability and user ownership — and make the next step feel doable.\n",
        "label": "Harvard-Architect-Pixar",
        "createdAt": "2025-12-19T04:49:07.939Z",
        "isActive": true
      }
    ],
    "activeSystemPromptId": "v5"
  },
  "defaultContext": {
    "path": "_default/",
    "maxBytes": 15000,
    "files": [
      "grove-overview.md",
      "key-concepts.md",
      "visionary-narrative.md"
    ]
  },
  "gcsFileMapping": {
    "ratchet-deep-dive.md": "The Grove Core Concepts The Ratchet Deep Dive 2c7780a78eef80e2acfbd49b84359d33.md",
    "ratchet-quantitative.md": "The Ratchet Quantitative Analysis 2c6780a78eef80ce84b4d5a3c0a18b7d.md",
    "edge-intelligence.md": "Why Edge Intelligence Is the Structural Answer to  2c9780a78eef8061a56efa68c190cbe4.md",
    "economics-deep-dive.md": "The Grove Economics Deep Dive 2c7780a78eef8109bd04c172e7ce8c88.md",
    "distributed-edge.md": "Distributed Edge Infrastructure Implications for G 2c8780a78eef80dfa4b6fbefd38f0eec.md",
    "infrastructure-provider.md": "The Grove as Distributed Infrastructure Provider 2c8780a78eef800ab8edca41bcb5f5dd.md",
    "everyday-ai.md": "The Grove as Everyday AI Infrastructure 2c7780a78eef806c8705dcd5605f6177.md",
    "simulation-deep-dive.md": "The Grove Simulation Deep Dive 2c7780a78eef801bae5cf150f185fc0b.md",
    "diary-deep-dive.md": "The Grove Diary System Deep Dive 2c7780a78eef80d38ac8e257a3e9d00d.md",
    "technical-architecture.md": "Grove Technical Architecture Reference 2c8780a78eef809990c9d57ff81e5b1a.md",
    "distributed-systems.md": "The Grove Distributed Systems Advances for Decentr 2c7780a78eef80008eb7e8630bed1f71.md",
    "engagement-research.md": "The Grove Engagement Research Brief 2c7780a78eef806c8fa2e6ab6f4dbe31.md"
  },
  "hubs": {
    "meta-philosophy": {
      "id": "meta-philosophy",
      "title": "You Are Already Here",
      "path": "hubs/meta-philosophy/",
      "primaryFile": "you-are-already-here.md",
      "status": "active",
      "tags": [
        "meta",
        "architecture",
        "simulation",
        "observer"
      ]
    },
    "infrastructure-bet": {
      "id": "infrastructure-bet",
      "title": "The $380B Infrastructure Bet",
      "path": "hubs/infrastructure-bet/",
      "primaryFile": "economics-deep-dive.md",
      "status": "active",
      "tags": [
        "$380 billion",
        "capex",
        "rent",
        "ownership"
      ]
    },
    "ratchet-effect": {
      "id": "ratchet-effect",
      "title": "The Ratchet Effect",
      "path": "hubs/ratchet-effect/",
      "primaryFile": "ratchet-deep-dive.md",
      "status": "active",
      "tags": [
        "ratchet",
        "doubling",
        "frontier"
      ]
    },
    "diary-system": {
      "id": "diary-system",
      "title": "The Diary System",
      "path": "hubs/diary-system/",
      "primaryFile": "diary-deep-dive.md",
      "status": "active",
      "tags": [
        "diary",
        "memory",
        "narrative"
      ]
    }
  },
  "journeys": {
    "simulation": {
      "id": "simulation",
      "title": "The Ghost in the Machine",
      "description": "You aren't just reading about The Grove. You are already inside it.",
      "entryNode": "sim-hook",
      "targetAha": "The Terminal is a single-node village. I am the proof of concept.",
      "linkedHubId": "meta-philosophy",
      "estimatedMinutes": 8,
      "status": "active"
    },
    "stakes": {
      "id": "stakes",
      "title": "The $380 Billion Bet",
      "description": "Follow the money. Why Big Tech is spending GDP-level capital to own your future.",
      "entryNode": "stakes-380b",
      "targetAha": "If you don't own the infrastructure, you are the product.",
      "linkedHubId": "infrastructure-bet",
      "estimatedMinutes": 12,
      "status": "active"
    },
    "ratchet": {
      "id": "ratchet",
      "title": "The Ratchet",
      "description": "Why AI capability is doubling every 7 months—and why you're 21 months behind.",
      "entryNode": "ratchet-hook",
      "linkedHubId": "ratchet-effect",
      "status": "active"
    }
  },
  "nodes": {
    "sim-hook": {
      "id": "sim-hook",
      "label": "Wait. Where are we, exactly?",
      "query": "Reveal the 'Moment of Recognition'. Explain that the Terminal isn't a website explaining Grove—it IS a Grove node. How is this simulation running the same patterns as the future network?",
      "contextSnippet": "You are already inside The Grove. Not metaphorically. Architecturally. The Terminal is a single-node simulation running the same patterns that will power distributed agent villages.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 1,
      "primaryNext": "sim-split",
      "alternateNext": [
        "sim-observer"
      ]
    },
    "sim-split": {
      "id": "sim-split",
      "label": "The invisible line in your own head.",
      "query": "Explain the 'Cognitive Split' using the user's own recent experience. How did the system handle their routine questions vs. their deep ones? Reveal the mechanics of the 'Efficiency-Enlightenment Loop'.",
      "contextSnippet": "You experienced the cognitive split without naming it. Routine cognition handled the basics. Frontier capability handled the synthesis. The system didn't just give you info—it waited until you were ready.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 2,
      "primaryNext": "sim-observer",
      "alternateNext": [
        "sim-recursion"
      ]
    },
    "sim-observer": {
      "id": "sim-observer",
      "label": "The thing that watches you read this.",
      "query": "Explain the 'Observer Dynamic' and 'Dramatic Irony'. How does the system's knowledge of the user's journey create a 'gardening' relationship? Why is this asymmetric knowledge benevolent?",
      "contextSnippet": "You know things the system doesn't. The system knows things you don't. This asymmetry isn't surveillance—it's cultivation. It's a relationship of care without control.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 3,
      "primaryNext": "sim-recursion",
      "alternateNext": [
        "sim-proof"
      ]
    },
    "sim-recursion": {
      "id": "sim-recursion",
      "label": "The loop closes.",
      "query": "Explain the 'Recursive Insight Structure'. How does this very document prove the architecture works? Discuss the 'Meta-Meta Insight'—that this revelation was programmatically triggered.",
      "contextSnippet": "The system evaluated your state and determined: 'this user is ready for the reveal.' The breakthrough you're experiencing was designed to happen. You are living inside the proof of concept.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 4,
      "primaryNext": "sim-proof",
      "alternateNext": [
        "stakes-380b"
      ]
    },
    "sim-proof": {
      "id": "sim-proof",
      "label": "You are the prototype.",
      "query": "Deliver 'The Invitation'. Frame the user not as a visitor, but as a participant/gardener in the first village. What does it mean to stay inside the system vs. returning to the outside view?",
      "contextSnippet": "You started as a visitor. You are now a participant. You have been gardening yourself through a system designed for gardening. Welcome to The Grove.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 5,
      "primaryNext": "stakes-380b",
      "alternateNext": [
        "ratchet-hook"
      ]
    },
    "stakes-380b": {
      "id": "stakes-380b",
      "label": "Someone is betting $380 billion they can own your mind.",
      "query": "Follow the money. Show me the $380B invoice. Why is Big Tech spending GDP-level capital on data centers? What are they buying that I'm about to lose?",
      "contextSnippet": "Microsoft, Google, Amazon, and Meta are collectively committing more to AI infrastructure than the GDP of most nations. This isn't a technology story. It's a power story.",
      "sectionId": "stakes",
      "journeyId": "stakes",
      "sequenceOrder": 1,
      "primaryNext": "stakes-rental",
      "alternateNext": [
        "stakes-ratchet"
      ]
    },
    "stakes-rental": {
      "id": "stakes-rental",
      "label": "The landlord of your own intelligence.",
      "query": "Explain 'renting intelligence'. If my AI remembers me, but that memory lives on a server I don't own, who actually owns the relationship? What happens when the landlord raises the rent?",
      "contextSnippet": "Your AI assistant remembers everything about you. But that memory lives on someone else's server. When the API changes, the relationship changes with it.",
      "sectionId": "stakes",
      "journeyId": "stakes",
      "sequenceOrder": 2,
      "primaryNext": "stakes-dependency",
      "alternateNext": [
        "sim-hook"
      ]
    },
    "stakes-dependency": {
      "id": "stakes-dependency",
      "label": "The trap isn't the cost. It's the convenience.",
      "query": "Explain the 'dependency trap'. How does the system become essential faster than I can adapt? Why is switching away from a rented brain impossible after six months?",
      "contextSnippet": "Every month you use an AI system, it learns more about how you work. Every month, switching becomes more painful. This is by design.",
      "sectionId": "stakes",
      "journeyId": "stakes",
      "sequenceOrder": 3,
      "primaryNext": "sim-hook",
      "alternateNext": [
        "ratchet-hook"
      ]
    },
    "ratchet-hook": {
      "id": "ratchet-hook",
      "label": "The 7-month clock.",
      "query": "Explain the Ratchet Effect. [REQUIRES: ratchet-deep-dive.md]",
      "sectionId": "ratchet",
      "journeyId": "ratchet",
      "primaryNext": "ratchet-gap"
    }
  }
}