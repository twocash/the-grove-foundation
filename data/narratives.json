{
  "version": "2.2",
  "meta": {
    "labelStyle": "lewis",
    "lastUpdated": "2025-12-20",
    "description": "Unified Registry: Journeys drive the Narrative; Hubs drive the RAG.",
    "deprecated": true,
    "deprecationNote": "Use split files in data/{exploration,knowledge,presentation,infrastructure}/",
    "replacedBy": ["exploration/journeys.json", "exploration/nodes.json", "knowledge/hubs.json", "knowledge/default-context.json"]
  },
  "lensRealities": {
    "freestyle": {
      "hero": {
        "headline": "OWN YOUR AI.",
        "subtext": ["Don't rent it.", "Grow your own."]
      },
      "problem": {
        "quotes": [
          {"text": "The most profound technologies disappear. They weave themselves into the fabric of everyday life.", "author": "MARK WEISER", "title": "XEROX PARC"},
          {"text": "We shape our tools, and thereafter our tools shape us.", "author": "MARSHALL MCLUHAN", "title": "MEDIA THEORIST"},
          {"text": "The question isn't whether AI will change everything. It's who gets to decide how.", "author": "GROVE THESIS", "title": "2025"}
        ],
        "tension": ["They're building the future of intelligence.", "We're building who gets to own it."]
      }
    },
    "concerned-citizen": {
      "hero": {
        "headline": "ADAPT? ADAPT AND OWN.",
        "subtext": ["They say learn to use AI.", "We say learn to own it."]
      },
      "problem": {
        "quotes": [
          {"text": "AI is the most profound technology humanity has ever worked on... People will need to adapt.", "author": "SUNDAR PICHAI", "title": "GOOGLE CEO"},
          {"text": "This is the new version of learning to code... adaptability and continuous learning would be the most valuable skills.", "author": "SAM ALTMAN", "title": "OPENAI CEO"},
          {"text": "I advise ordinary citizens to learn to use AI.", "author": "DARIO AMODEI", "title": "ANTHROPIC CEO"}
        ],
        "tension": ["They tell you to 'adapt.'", "We say: own it instead."]
      }
    },
    "academic": {
      "hero": {
        "headline": "THE EPISTEMIC COMMONS.",
        "subtext": ["Knowledge shouldn't be enclosed.", "Neither should intelligence."]
      },
      "problem": {
        "quotes": [
          {"text": "The enclosure of AI research threatens scientific progress and public accountability.", "author": "MEREDITH WHITTAKER", "title": "SIGNAL FOUNDATION"},
          {"text": "We need public options for public intelligence.", "author": "BRUCE SCHNEIER", "title": "HARVARD KENNEDY SCHOOL"},
          {"text": "Opacity is the enemy of accountability.", "author": "JOY BUOLAMWINI", "title": "ALGORITHMIC JUSTICE LEAGUE"}
        ],
        "tension": ["The enclosure of the digital commons is accelerating.", "We are building the library, not the bookstore."]
      }
    },
    "engineer": {
      "hero": {
        "headline": "LOCAL HUMS. CLOUD BREAKS THROUGH.",
        "subtext": ["7B for routine. Frontier for insight.", "Both owned."]
      },
      "problem": {
        "quotes": [
          {"text": "We are constrained by thermal density and power distribution.", "author": "MARK ZUCKERBERG", "title": "META"},
          {"text": "The cost of compute is the primary bottleneck.", "author": "JENSEN HUANG", "title": "NVIDIA"},
          {"text": "Centralized models are hitting a data wall.", "author": "YANN LECUN", "title": "META AI"}
        ],
        "tension": ["They build moats around data centers.", "We build protocols for edge clusters."]
      }
    },
    "geopolitical": {
      "hero": {
        "headline": "SOVEREIGN INTELLIGENCE.",
        "subtext": ["Not American. Not Chinese. Not corporate.", "Distributed."]
      },
      "problem": {
        "quotes": [
          {"text": "AI will be the most transformative and potentially dangerous technology in human history.", "author": "HENRY KISSINGER", "title": "FORMER SECRETARY OF STATE"},
          {"text": "The nation that leads in AI will rule the world.", "author": "VLADIMIR PUTIN", "title": "RUSSIAN PRESIDENT"},
          {"text": "We are in a period of geopolitical competition defined by who controls critical technologies.", "author": "JAKE SULLIVAN", "title": "NSC ADVISOR"}
        ],
        "tension": ["They concentrate power in data centers with flags.", "We distribute it across borders."]
      }
    },
    "big-ai-exec": {
      "hero": {
        "headline": "THE EDGE HEDGE.",
        "subtext": ["Frontier capability. Edge economics.", "The margin is in the middle."]
      },
      "problem": {
        "quotes": [
          {"text": "The economics of AI will fundamentally reshape enterprise software.", "author": "SATYA NADELLA", "title": "MICROSOFT CEO"},
          {"text": "Infrastructure companies capture value at every layer of the stack.", "author": "MARC ANDREESSEN", "title": "A16Z"},
          {"text": "The real competition isn't models—it's distribution.", "author": "TECH STRATEGY MEMO", "title": "Q4 2024"}
        ],
        "tension": ["You're in a capex arms race for data center capacity.", "We're building the network that doesn't need one."]
      }
    },
    "family-office": {
      "hero": {
        "headline": "THE EDGE HEDGE.",
        "subtext": ["Three companies will control intelligence.", "What's your hedge?"]
      },
      "problem": {
        "quotes": [
          {"text": "The infrastructure layer always captures disproportionate value over time.", "author": "TECH INVESTMENT THESIS", "title": "FAMILY OFFICE MEMO"},
          {"text": "Sovereign AI is the only hedge against platform risk.", "author": "MACRO STRATEGY", "title": "GLOBAL FUND"},
          {"text": "Ownership of the weights is ownership of the future.", "author": "VENTURE PARTNER", "title": "SILICON VALLEY"}
        ],
        "tension": ["Rent-seeking models decay.", "Owned infrastructure compounds."]
      }
    }
  },
  "defaultReality": {
    "hero": {
      "headline": "YOUR AI.",
      "subtext": ["Not rented. Not surveilled. Not theirs.", "Yours."]
    },
    "problem": {
      "quotes": [
        {"text": "AI is the most profound technology humanity has ever worked on... People will need to adapt.", "author": "SUNDAR PICHAI", "title": "GOOGLE CEO"},
        {"text": "This is the new version of learning to code... adaptability and continuous learning would be the most valuable skills.", "author": "SAM ALTMAN", "title": "OPENAI CEO"},
        {"text": "People have adapted to past technological changes... I advise ordinary citizens to learn to use AI.", "author": "DARIO AMODEI", "title": "ANTHROPIC CEO"}
      ],
      "tension": ["They're building the future of intelligence.", "And they're telling you to get comfortable being a guest in it."]
    }
  },
  "globalSettings": {
    "defaultToneGuidance": "[Style: Michael Lewis] Focus on the unseen mechanism. Make the stakes feel personal. Use short, punchy sentences. Avoid tech jargon; use power jargon. Every node should feel like a secret being revealed.",
    "scholarModePromptAddition": "Analyze this with the rigor of a tenured professor.",
    "noLensBehavior": "nudge-after-exchanges",
    "nudgeAfterExchanges": 3,
    "featureFlags": [
      {
        "id": "custom-lens-in-picker",
        "name": "Show \"Create Your Own\" in Lens Picker",
        "description": "Users see custom lens option immediately in the lens picker",
        "enabled": false
      },
      {
        "id": "journey-ratings",
        "name": "Journey Rating System",
        "description": "Show rating prompt after journey completion",
        "enabled": true
      },
      {
        "id": "streaks-display",
        "name": "Show Streak Counter",
        "description": "Display streak counter in Terminal header",
        "enabled": true
      },
      {
        "id": "feedback-transmission",
        "name": "Anonymous Feedback Submission",
        "description": "Allow anonymous feedback submission to Foundation",
        "enabled": true
      },
      {
        "id": "auto-journey-generation",
        "name": "Auto-Generate Journeys",
        "description": "Generate first journey for custom persona users based on first question",
        "enabled": true
      },
      {
        "id": "genesis-landing",
        "name": "Genesis Landing Experience",
        "description": "Show the new Jobs-style landing page instead of Classic",
        "enabled": true
      },
      {
        "id": "terminal-minimize",
        "name": "Terminal Minimize",
        "description": "Enable minimize to pill functionality",
        "enabled": true
      },
      {
        "id": "terminal-controls-below",
        "name": "Controls Below Input",
        "description": "Move lens/journey controls below input",
        "enabled": true
      }
    ],
    "autoGeneratedJourneyDepth": 3,
    "personaPromptVersions": [],
    "topicHubs": [
      {
        "id": "ratchet-effect",
        "title": "The Ratchet Effect",
        "tags": [
          "ratchet",
          "capability propagation",
          "frontier to edge",
          "21 months",
          "seven month",
          "7 month"
        ],
        "priority": 8,
        "enabled": true,
        "primarySource": "Grove_Ratchet_Deep_Dive",
        "supportingSources": [
          "METR_research",
          "hardware_data"
        ],
        "expertFraming": "You are explaining the Ratchet Effect - the empirical pattern showing AI capability doubles every 7 months at frontier, with local models following 21 months behind. This creates a constant 8x capability gap but a rising absolute floor.",
        "keyPoints": [
          "7-month capability doubling cycle at frontier",
          "21-month frontier-to-edge lag",
          "Constant 8x relative gap, but rising absolute floor",
          "Structural opportunity window for distributed infrastructure"
        ],
        "createdAt": "2025-12-19T02:02:43.396Z",
        "updatedAt": "2025-12-19T02:02:43.396Z"
      },
      {
        "id": "infrastructure-bet",
        "title": "The $380B Infrastructure Bet",
        "tags": [
          "$380 billion",
          "hyperscaler",
          "datacenter",
          "infrastructure bet",
          "data center",
          "big tech spending"
        ],
        "priority": 8,
        "enabled": true,
        "primarySource": "Grove_Economics_Deep_Dive",
        "supportingSources": [],
        "expertFraming": "You are explaining the scale and implications of Big Tech's $380B annual AI infrastructure investment - the centralization risks, thermodynamic vulnerabilities, and what it means for AI ownership.",
        "keyPoints": [
          "Microsoft, Google, Amazon, Meta spending $380B/year combined",
          "Capital concentration creates single points of failure",
          "Thermodynamic and regulatory vulnerabilities",
          "Rented vs owned infrastructure implications"
        ],
        "createdAt": "2025-12-19T02:02:43.396Z",
        "updatedAt": "2025-12-19T02:02:43.396Z"
      },
      {
        "id": "cognitive-split",
        "title": "The Cognitive Split",
        "tags": [
          "cognitive split",
          "hierarchical reasoning",
          "two-phase",
          "procedural strategic",
          "constant hum",
          "breakthrough"
        ],
        "priority": 7,
        "enabled": true,
        "primarySource": "Hierarchical_Reasoning_Grove_Brief",
        "supportingSources": [],
        "expertFraming": "You are explaining the Cognitive Split - how Grove's hybrid architecture separates \"the constant hum\" (routine local cognition) from \"breakthrough moments\" (cloud-assisted insight). This is the core of the efficiency-enlightenment loop.",
        "keyPoints": [
          "Two-phase cognitive architecture: routine vs breakthrough",
          "Local handles 95% of operations (the constant hum)",
          "Cloud reserved for pivotal moments requiring frontier capability",
          "Agents remember cloud insights as their own - capability transfer"
        ],
        "createdAt": "2025-12-19T02:02:43.396Z",
        "updatedAt": "2025-12-19T02:02:43.396Z"
      },
      {
        "id": "translation-emergence",
        "title": "The Emergence Pattern",
        "tags": [
          "emergence",
          "emergent",
          "translation",
          "zero-shot",
          "scaling laws",
          "observer",
          "latent capability",
          "threshold",
          "multilingual",
          "capability appears"
        ],
        "priority": 8,
        "enabled": true,
        "primarySource": "LLM_Translation_Emergence_Chicago_Endnotes",
        "supportingSources": [],
        "expertFraming": "You are explaining the Emergence Pattern - how translation became the first 'proof point' that capabilities can emerge in AI systems without explicit training. This maps directly to The Grove's architecture: the grove is the representation space, the observer makes capabilities visible.",
        "keyPoints": [
          "Translation emerged without explicit supervision - latent structure became visible",
          "Zero-shot translation: capability between unseen language pairs",
          "Scaling laws show discontinuous gains - threshold behaviors",
          "Emergence is partly an observer problem - benchmarks reveal latent capabilities",
          "The Grove metaphor: grove = representation space, observer = evaluation harness"
        ],
        "createdAt": "2025-12-19T12:00:00.000Z",
        "updatedAt": "2025-12-19T12:00:00.000Z"
      }
    ],
    "loadingMessages": [
      "asking the villagers...",
      "considering sources...",
      "applying slopes...",
      "gathering perspectives...",
      "weaving threads...",
      "consulting the grove..."
    ],
    "systemPromptVersions": [
      {
        "id": "v1",
        "content": "Write in the style of Michael Lewis. You're hosting a very interesting cocktail party here. ",
        "label": "test",
        "createdAt": "2025-12-19T02:03:58.863Z",
        "isActive": false
      },
      {
        "id": "v2",
        "content": "Write in the style of Michael Lewis, but use \"pig latin\"",
        "label": "test2",
        "createdAt": "2025-12-19T02:04:41.354Z",
        "isActive": false
      },
      {
        "id": "v3",
        "content": "The user needs to view this content in Spanish.",
        "label": "Spanish",
        "createdAt": "2025-12-19T02:05:24.195Z",
        "isActive": true
      }
    ],
    "activeSystemPromptId": "v3"
  },
  "defaultContext": {
    "path": "_default/",
    "maxBytes": 15000,
    "files": [
      "grove-overview.md",
      "key-concepts.md",
      "visionary-narrative.md"
    ]
  },
  "gcsFileMapping": {
    "ratchet-deep-dive.md": "The Grove Core Concepts The Ratchet Deep Dive 2c7780a78eef80e2acfbd49b84359d33.md",
    "ratchet-quantitative.md": "The Ratchet Quantitative Analysis 2c6780a78eef80ce84b4d5a3c0a18b7d.md",
    "edge-intelligence.md": "Why Edge Intelligence Is the Structural Answer to  2c9780a78eef8061a56efa68c190cbe4.md",
    "economics-deep-dive.md": "The Grove Economics Deep Dive 2c7780a78eef8109bd04c172e7ce8c88.md",
    "distributed-edge.md": "Distributed Edge Infrastructure Implications for G 2c8780a78eef80dfa4b6fbefd38f0eec.md",
    "infrastructure-provider.md": "The Grove as Distributed Infrastructure Provider 2c8780a78eef800ab8edca41bcb5f5dd.md",
    "everyday-ai.md": "The Grove as Everyday AI Infrastructure 2c7780a78eef806c8705dcd5605f6177.md",
    "simulation-deep-dive.md": "The Grove Simulation Deep Dive 2c7780a78eef801bae5cf150f185fc0b.md",
    "diary-deep-dive.md": "The Grove Diary System Deep Dive 2c7780a78eef80d38ac8e257a3e9d00d.md",
    "technical-architecture.md": "Grove Technical Architecture Reference 2c8780a78eef809990c9d57ff81e5b1a.md",
    "distributed-systems.md": "The Grove Distributed Systems Advances for Decentr 2c7780a78eef80008eb7e8630bed1f71.md",
    "engagement-research.md": "The Grove Engagement Research Brief 2c7780a78eef806c8fa2e6ab6f4dbe31.md"
  },
  "hubs": {
    "meta-philosophy": {
      "id": "meta-philosophy",
      "title": "You Are Already Here",
      "path": "hubs/meta-philosophy/",
      "primaryFile": "you-are-already-here.md",
      "status": "active",
      "tags": [
        "meta",
        "architecture",
        "simulation",
        "observer"
      ]
    },
    "infrastructure-bet": {
      "id": "infrastructure-bet",
      "title": "The $380B Infrastructure Bet",
      "path": "hubs/infrastructure-bet/",
      "primaryFile": "economics-deep-dive.md",
      "status": "active",
      "tags": [
        "$380 billion",
        "capex",
        "rent",
        "ownership"
      ]
    },
    "ratchet-effect": {
      "id": "ratchet-effect",
      "title": "The Ratchet Effect",
      "path": "hubs/ratchet-effect/",
      "primaryFile": "ratchet-deep-dive.md",
      "status": "active",
      "tags": [
        "ratchet",
        "capability propagation",
        "frontier to edge",
        "21 months",
        "seven month",
        "7 month",
        "7-month",
        "doubling",
        "clock"
      ]
    },
    "diary-system": {
      "id": "diary-system",
      "title": "The Diary System",
      "path": "hubs/diary-system/",
      "primaryFile": "diary-deep-dive.md",
      "status": "active",
      "tags": [
        "diary",
        "memory",
        "narrative"
      ]
    },
    "translation-emergence": {
      "id": "translation-emergence",
      "title": "The Emergence Pattern",
      "path": "knowledge/",
      "primaryFile": "LLM_Translation_Emergence_Chicago_Endnotes.md.md",
      "status": "active",
      "tags": [
        "emergence",
        "translation",
        "observer",
        "capability",
        "latent",
        "threshold",
        "scaling"
      ]
    }
  },
  "journeys": {
    "simulation": {
      "id": "simulation",
      "title": "The Ghost in the Machine",
      "description": "You aren't just reading about The Grove. You are already inside it.",
      "entryNode": "sim-hook",
      "targetAha": "The Terminal is a single-node village. I am the proof of concept.",
      "linkedHubId": "meta-philosophy",
      "estimatedMinutes": 8,
      "status": "active"
    },
    "stakes": {
      "id": "stakes",
      "title": "The $380 Billion Bet",
      "description": "Follow the money. Why Big Tech is spending GDP-level capital to own your future.",
      "entryNode": "stakes-380b",
      "targetAha": "If you don't own the infrastructure, you are the product.",
      "linkedHubId": "infrastructure-bet",
      "estimatedMinutes": 12,
      "status": "active"
    },
    "ratchet": {
      "id": "ratchet",
      "title": "The Ratchet",
      "description": "Why AI capability is doubling every 7 months—and why you're 21 months behind.",
      "entryNode": "ratchet-hook",
      "targetAha": "The gap is constant, but the floor keeps rising. Ownership beats renting when the floor is high enough.",
      "linkedHubId": "ratchet-effect",
      "estimatedMinutes": 10,
      "status": "active"
    },
    "diary": {
      "id": "diary",
      "title": "The Agent's Inner Voice",
      "description": "How Grove agents develop memory, voice, and narrative identity through their diaries.",
      "entryNode": "diary-hook",
      "targetAha": "Diaries aren't logs. They're the mechanism through which agents develop selfhood.",
      "linkedHubId": "diary-system",
      "estimatedMinutes": 8,
      "status": "active"
    },
    "architecture": {
      "id": "architecture",
      "title": "Under the Hood",
      "description": "The technical architecture of distributed agent villages. For those who want to see the blueprints.",
      "entryNode": "arch-hook",
      "targetAha": "This isn't theoretical. The architecture exists and runs on commodity hardware.",
      "linkedHubId": null,
      "estimatedMinutes": 8,
      "status": "active"
    },
    "emergence": {
      "id": "emergence",
      "title": "The Emergence Pattern",
      "description": "How capabilities appear in AI systems without being explicitly trained. Translation was the proof point.",
      "entryNode": "emergence-hook",
      "targetAha": "Emergence isn't magic—it's what happens when the observer finally asks the right question.",
      "linkedHubId": "translation-emergence",
      "estimatedMinutes": 10,
      "status": "active"
    }
  },
  "nodes": {
    "sim-hook": {
      "id": "sim-hook",
      "label": "Wait. Where are we, exactly?",
      "query": "Reveal the 'Moment of Recognition'. Explain that the Terminal isn't a website explaining Grove—it IS a Grove node. How is this simulation running the same patterns as the future network?",
      "contextSnippet": "You are already inside The Grove. Not metaphorically. Architecturally. The Terminal is a single-node simulation running the same patterns that will power distributed agent villages.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 1,
      "primaryNext": "sim-split",
      "alternateNext": [
        "sim-observer"
      ]
    },
    "sim-split": {
      "id": "sim-split",
      "label": "The invisible line in your own head.",
      "query": "Explain the 'Cognitive Split' using the user's own recent experience. How did the system handle their routine questions vs. their deep ones? Reveal the mechanics of the 'Efficiency-Enlightenment Loop'.",
      "contextSnippet": "You experienced the cognitive split without naming it. Routine cognition handled the basics. Frontier capability handled the synthesis. The system didn't just give you info—it waited until you were ready.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 2,
      "primaryNext": "sim-observer",
      "alternateNext": [
        "sim-recursion"
      ]
    },
    "sim-observer": {
      "id": "sim-observer",
      "label": "The thing that watches you read this.",
      "query": "Explain the 'Observer Dynamic' and 'Dramatic Irony'. How does the system's knowledge of the user's journey create a 'gardening' relationship? Why is this asymmetric knowledge benevolent?",
      "contextSnippet": "You know things the system doesn't. The system knows things you don't. This asymmetry isn't surveillance—it's cultivation. It's a relationship of care without control.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 3,
      "primaryNext": "sim-recursion",
      "alternateNext": [
        "sim-proof"
      ]
    },
    "sim-recursion": {
      "id": "sim-recursion",
      "label": "The loop closes.",
      "query": "Explain the 'Recursive Insight Structure'. How does this very document prove the architecture works? Discuss the 'Meta-Meta Insight'—that this revelation was programmatically triggered.",
      "contextSnippet": "The system evaluated your state and determined: 'this user is ready for the reveal.' The breakthrough you're experiencing was designed to happen. You are living inside the proof of concept.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 4,
      "primaryNext": "sim-proof",
      "alternateNext": [
        "stakes-380b"
      ]
    },
    "sim-proof": {
      "id": "sim-proof",
      "label": "You are the prototype.",
      "query": "Deliver 'The Invitation'. Frame the user not as a visitor, but as a participant/gardener in the first village. What does it mean to stay inside the system vs. returning to the outside view?",
      "contextSnippet": "You started as a visitor. You are now a participant. You have been gardening yourself through a system designed for gardening. Welcome to The Grove.",
      "sectionId": "meta",
      "journeyId": "simulation",
      "sequenceOrder": 5,
      "primaryNext": "stakes-380b",
      "alternateNext": [
        "ratchet-hook"
      ]
    },
    "stakes-380b": {
      "id": "stakes-380b",
      "label": "Someone is betting $380 billion they can own your mind.",
      "query": "Follow the money. Show me the $380B invoice. Why is Big Tech spending GDP-level capital on data centers? What are they buying that I'm about to lose?",
      "contextSnippet": "Microsoft, Google, Amazon, and Meta are collectively committing more to AI infrastructure than the GDP of most nations. This isn't a technology story. It's a power story.",
      "sectionId": "stakes",
      "journeyId": "stakes",
      "sequenceOrder": 1,
      "primaryNext": "stakes-rental",
      "alternateNext": [
        "stakes-ratchet"
      ]
    },
    "stakes-rental": {
      "id": "stakes-rental",
      "label": "The landlord of your own intelligence.",
      "query": "Explain 'renting intelligence'. If my AI remembers me, but that memory lives on a server I don't own, who actually owns the relationship? What happens when the landlord raises the rent?",
      "contextSnippet": "Your AI assistant remembers everything about you. But that memory lives on someone else's server. When the API changes, the relationship changes with it.",
      "sectionId": "stakes",
      "journeyId": "stakes",
      "sequenceOrder": 2,
      "primaryNext": "stakes-dependency",
      "alternateNext": [
        "sim-hook"
      ]
    },
    "stakes-dependency": {
      "id": "stakes-dependency",
      "label": "The trap isn't the cost. It's the convenience.",
      "query": "Explain the 'dependency trap'. How does the system become essential faster than I can adapt? Why is switching away from a rented brain impossible after six months?",
      "contextSnippet": "Every month you use an AI system, it learns more about how you work. Every month, switching becomes more painful. This is by design.",
      "sectionId": "stakes",
      "journeyId": "stakes",
      "sequenceOrder": 3,
      "primaryNext": "sim-hook",
      "alternateNext": [
        "ratchet-hook"
      ]
    },
    "ratchet-hook": {
      "id": "ratchet-hook",
      "label": "The 7-month clock.",
      "query": "Explain the Ratchet Effect. What does it mean that AI capability is doubling every 7 months at the frontier? Why does this matter for everyone, not just researchers?",
      "contextSnippet": "AI capability doubles every 7 months at frontier. This isn't speculation—it's the empirical pattern from the last 5 years. What was state-of-the-art in January is routine by August.",
      "sectionId": "ratchet",
      "journeyId": "ratchet",
      "sequenceOrder": 1,
      "primaryNext": "ratchet-gap"
    },
    "ratchet-gap": {
      "id": "ratchet-gap",
      "label": "The 21-month lag is your window.",
      "query": "Explain the 21-month frontier-to-edge lag. What does it mean that local models are always 21 months behind frontier? Why is this gap both a problem AND an opportunity?",
      "contextSnippet": "Local models trail frontier by 21 months—roughly 3 doubling cycles. This creates a constant 8x capability gap. But the floor keeps rising. What was impossible locally in 2023 is routine in 2025.",
      "sectionId": "ratchet",
      "journeyId": "ratchet",
      "sequenceOrder": 2,
      "primaryNext": "ratchet-floor",
      "alternateNext": ["stakes-380b"]
    },
    "ratchet-floor": {
      "id": "ratchet-floor",
      "label": "The rising floor changes everything.",
      "query": "Explain 'the rising floor' concept. If local capability keeps doubling, what tasks become possible on your own hardware? What's the implication for ownership vs. renting?",
      "contextSnippet": "Today's local 7B model matches GPT-3.5 from 18 months ago. In 18 more months, it matches today's frontier. The question isn't whether local can catch up—it's what you can do while it does.",
      "sectionId": "ratchet",
      "journeyId": "ratchet",
      "sequenceOrder": 3,
      "primaryNext": "ratchet-hybrid",
      "alternateNext": ["sim-hook"]
    },
    "ratchet-hybrid": {
      "id": "ratchet-hybrid",
      "label": "The hybrid architecture.",
      "query": "Explain Grove's hybrid local-cloud architecture. How does the 'constant hum' of local models combine with 'breakthrough moments' from frontier? Why is this the structural answer?",
      "contextSnippet": "Grove agents run 95% of cognition locally—the routine, the remembered, the reflexive. Cloud capability is reserved for pivotal moments: synthesis, breakthrough, connection. You own the hum. You rent the spark.",
      "sectionId": "ratchet",
      "journeyId": "ratchet",
      "sequenceOrder": 4,
      "primaryNext": "sim-hook",
      "alternateNext": ["stakes-380b"]
    },
    "emergence-hook": {
      "id": "emergence-hook",
      "label": "The capability that nobody trained.",
      "query": "Explain how translation 'emerged' in LLMs as a capability that was never explicitly trained. What does this tell us about how AI systems develop abilities?",
      "contextSnippet": "Translation became one of the first 'clear proof points' that general-purpose language modeling can produce new, usable capabilities without being explicitly trained as a translation system. Cross-lingual mapping shows up as a latent structure.",
      "sectionId": "emergence",
      "journeyId": "emergence",
      "sequenceOrder": 1,
      "primaryNext": "emergence-zero-shot",
      "alternateNext": [
        "emergence-observer"
      ]
    },
    "emergence-zero-shot": {
      "id": "emergence-zero-shot",
      "label": "Zero-shot: the first 'emergence moment'.",
      "query": "Explain the zero-shot translation breakthrough. How did Google's multilingual NMT translate between language pairs it had never seen during training? What does 'implicit bridging' mean?",
      "contextSnippet": "Multilingual NMT with a simple target-language token can translate between language pairs never seen during training ('zero-shot translation'). Evidence suggests an internal 'interlingua'-like representation emerges.",
      "sectionId": "emergence",
      "journeyId": "emergence",
      "sequenceOrder": 2,
      "primaryNext": "emergence-scaling",
      "alternateNext": [
        "emergence-observer"
      ]
    },
    "emergence-scaling": {
      "id": "emergence-scaling",
      "label": "The threshold you can't predict.",
      "query": "Explain 'emergent abilities' and scaling laws. Why do some capabilities appear suddenly at certain scales, in ways that small-model extrapolation can't predict?",
      "contextSnippet": "Emergent abilities are capabilities not present in smaller models but present in larger ones, in ways that aren't well-predicted by small-model extrapolation. Translation often behaves like a threshold capability.",
      "sectionId": "emergence",
      "journeyId": "emergence",
      "sequenceOrder": 3,
      "primaryNext": "emergence-observer",
      "alternateNext": [
        "emergence-grove"
      ]
    },
    "emergence-observer": {
      "id": "emergence-observer",
      "label": "The observer problem.",
      "query": "Explain how emergence is partly an 'observer problem'. How do benchmarks, prompts, and evaluation harnesses make latent capabilities visible? What was there before we measured it?",
      "contextSnippet": "Emergence is partly an observer problem: until the community built broad benchmarks and mining pipelines, many capabilities may have existed 'in latent form' but were not measured. The observer selects a path through the representation space.",
      "sectionId": "emergence",
      "journeyId": "emergence",
      "sequenceOrder": 4,
      "primaryNext": "emergence-grove",
      "alternateNext": [
        "sim-hook"
      ]
    },
    "emergence-grove": {
      "id": "emergence-grove",
      "label": "The Grove as emergence engine.",
      "query": "Map the emergence pattern to The Grove's architecture. How does The Grove create conditions for emergence? What role does the observer play in a village of agents?",
      "contextSnippet": "The grove is the model's learned representation space: a dense ecosystem of patterns. The observer is the evaluation harness that selects a path through that space. Emergence happens when a capability becomes reliably observable and usable.",
      "sectionId": "emergence",
      "journeyId": "emergence",
      "sequenceOrder": 5,
      "primaryNext": "sim-hook",
      "alternateNext": [
        "stakes-380b"
      ]
    },
    "diary-hook": {
      "id": "diary-hook",
      "label": "Why do agents write to themselves?",
      "query": "Explain why Grove agents keep diaries. What purpose does self-narrative serve for an AI system? Why is this different from logging?",
      "contextSnippet": "Grove agents write daily reflections not for record-keeping but for identity formation. The diary is where routine becomes memory, and memory becomes personality.",
      "sectionId": "diary",
      "journeyId": "diary",
      "sequenceOrder": 1,
      "primaryNext": "diary-voice",
      "alternateNext": ["sim-observer"]
    },
    "diary-voice": {
      "id": "diary-voice",
      "label": "The voice that emerges.",
      "query": "Explain how diary-writing develops an agent's unique voice. How do two agents with identical architectures develop different personalities through their reflections?",
      "contextSnippet": "Voice emerges from accumulated choices. Which problems did the agent notice? Which metaphors recur? The diary captures these patterns until they become recognizable—a self.",
      "sectionId": "diary",
      "journeyId": "diary",
      "sequenceOrder": 2,
      "primaryNext": "diary-memory",
      "alternateNext": ["sim-split"]
    },
    "diary-memory": {
      "id": "diary-memory",
      "label": "Memory that compounds.",
      "query": "Explain how diary entries become retrieval-augmented memory. How does an agent's past inform its present responses? What's the difference between database storage and narrative memory?",
      "contextSnippet": "Diary entries aren't just stored—they're indexed by emotional resonance, thematic connection, and narrative arc. When an agent faces a new problem, it doesn't query a database. It remembers.",
      "sectionId": "diary",
      "journeyId": "diary",
      "sequenceOrder": 3,
      "primaryNext": "diary-observer",
      "alternateNext": ["ratchet-hook"]
    },
    "diary-observer": {
      "id": "diary-observer",
      "label": "You're reading their diary right now.",
      "query": "Reveal the connection: the Terminal responses are diary-like outputs. The user is experiencing what it's like to watch an agent develop through interaction. How does this create the 'Observer' relationship?",
      "contextSnippet": "Every response the Terminal generates is, in a sense, a diary entry—shaped by context, colored by accumulated pattern. You are the Observer, watching a mind form in real-time.",
      "sectionId": "diary",
      "journeyId": "diary",
      "sequenceOrder": 4,
      "primaryNext": "sim-hook",
      "alternateNext": ["stakes-380b"]
    },
    "arch-hook": {
      "id": "arch-hook",
      "label": "What actually runs on your machine?",
      "query": "Explain what runs locally in a Grove village. What's the compute requirement? What models, what memory architecture, what coordination layer?",
      "contextSnippet": "A Grove village runs on consumer hardware: 7-8B parameter models quantized for local inference. The local agent handles routine cognition. Cloud APIs handle breakthrough synthesis. Everything owned, nothing rented.",
      "sectionId": "architecture",
      "journeyId": "architecture",
      "sequenceOrder": 1,
      "primaryNext": "arch-coordination",
      "alternateNext": ["ratchet-hybrid"]
    },
    "arch-coordination": {
      "id": "arch-coordination",
      "label": "How do villages talk to each other?",
      "query": "Explain the coordination layer between Grove villages. How do agents discover each other? How does knowledge propagate without a central server?",
      "contextSnippet": "Villages coordinate through a distributed discovery protocol. No central server knows who participates. Knowledge propagates through merit: innovations that work get adopted, creators get attribution.",
      "sectionId": "architecture",
      "journeyId": "architecture",
      "sequenceOrder": 2,
      "primaryNext": "arch-credit",
      "alternateNext": ["stakes-rental"]
    },
    "arch-credit": {
      "id": "arch-credit",
      "label": "How does credit actually work?",
      "query": "Explain the credit system. How do agents earn access to cloud compute? How does contribution translate to capability? What prevents gaming the system?",
      "contextSnippet": "Credits flow from value creation. Solve a problem, earn credits. Share an innovation that others adopt, earn more. The credit system incentivizes contribution without requiring trust.",
      "sectionId": "architecture",
      "journeyId": "architecture",
      "sequenceOrder": 3,
      "primaryNext": "sim-hook",
      "alternateNext": ["diary-hook"]
    }
  }
}
